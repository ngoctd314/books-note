
# Go 101

## About Go 101

Thinking Go is easy to master is considered harmful. Holding such opinion (thinking Go is easy to master) will make you understand Go shallowly and prevent you from mastering Go.

**What are the selling points of Go go you think?**

Personally, i think the fact that, as a static language, Go is flexible as many dynamic script languages is the main selling point of Go language.

Memory saving, fast program warming-up, fast code execution speed and fast compilations combined is another main selling point of Go.

Built-in concurrent programming support is also a selling point of Go, though personally I don't think it is the main selling point of Go.

Great code readability is another important selling point of Go. 

Great cross-platform support is also a selling point of Go.

## An Introduction of Go
Go is compiled and static typed programming language born from Google.

Go has many features.

- Built-in concurrent programming support: goroutines, channels (based on CSP model)
- The container types map and slice are first-class citizens
- Polymorphism through interfaces
- Value boxing and reflection through interfaces
- Pointers
- Function closures
- Methods
- Deferred function calls
- Type embedding
- Type deduction
- Memory safety
- Automatic garbage collection
- Great cross-platform compatibility
- Custom generics

## The Go Toolchain

GOPATH is defaulted to the path to the go folder under the home directory of the current user. GOPATH contains

- The pkg subfolder under the GOPATH folder is used to store cached versions of Go modules
- There is a GOBIN environment variable which controls where Go program binary files generated by the go install subcommand will be stored. The value of the GOBIN env variable is defaulted to the path to bin subfolder under the GOPATH folder.

## Constants and variables

**Untyped values and Typed Values**
In Go, some values are untyped. An untyped value means the type of the value has not been confirmed yet. On the contrary, the type of a typed value is determined.

For most untyped values, each of them has one default type. The predeclared nil is the only untyped value which has no default type. 

All literal constants (unnamed constants) are untyped values. 

**Explicit Conversions of Untyped Constants**

Go supports value conversions. We can use the form T(v) to convert a value v to the type denoted by T (or simply speaking, type T). If the conversions T(v) is legal, Go compilers view T(v) as a typed value of type T. Surely, for a certain type T, to make conversion T(v) legal, the value v can't be arbitrary.

**Type Deductions in Go**
Go supports type deduction. In other words, in many circumstances, programmers don't need to explicitly specify the types of some values in code. Go compilers will deduce the types for these values by context.

Type deduction is also often called type inference.

**iota in constant declarations**

The autocomplete feature plus the iota constant generator feature brings much convenience to go programming. 

**Variables, variable declarations and value**

Variables are named values. Variables are stored in memory at run time. The value represented by a variable can be modified at run time.

**Value Addressability**

In Go, some values are addressable (there is an address to find them). All variables are addressable and all constants are unaddressable. 

## Goroutines, Deferred Function Calls and Panic/Recover

**Goroutines**

Modern CPUs often have multiple cores, and some CPU cores support hyper-threading. In other words, modern CPUs can process multiple instruction pipelines simultaneously. To fully use the power of modern CPUs, we need to do concurrent programming in coding our programs.

When the main goroutine exits, the whole program also exits, even if there are still some other goroutines which have not exited yet.

**Goroutine States**
A live goroutine may stay in (and switch between) two states, running and blocking. Note, a goroutine is still considered to be running if it is asleep (after calling time.Sleep function) or awaiting the response of a system call or a network connection.

When a goroutine is created, it will enter running state automatically. Goroutines can only exist from running state, and never from blocking state. If, for any reason, a goroutine stays in blocking state forever, then it will never exit.

A blocking goroutine can only be unblocked by an operation made in another goroutine. If all goroutines in a Go program are in blocking state, then all of them will stay in blocking state forever. This can be viewed as an deadlock.

**Goroutine Schedule**
Not all goroutines in running state are being executed at a given time. At any given time, the maximum number of goroutines being executed will not exceed the number of logical CPUs available for the current program. Each logical CPU can only execute one goroutine at any given time. Goroutine must frequently switch execution contexts between goroutines to let each running goroutine have a chance to execute. This is similar to how operating systems which execution contexts between OS threads.

## Go Type System Overview

**Composite Types**
**Underlying Types**
**Value Parts**
At runtime, many values are stored somewhere in memory. In Go, each of such values has a direct part. However, some of them have one or more indirect parts. Each value part occupies a continuous memory segment.
**Types Which Support or Don't Support Comparision**
Go doesn't support comparisions for values of the following types: slice, map, function, struct
Above listed types are called incomparable types. All other types are called comparable types.

## Pointers in Go

### Memory Addresses

Generally, a memory address is stored as an unsigned native word. The size of native work is 4 bytes on 32-bit architectures and 8 bytes on 64-bit architectures.

### Value Addresses
The address of a value means that the start address of the memory segment occupied by the direct part of the value.

## Structs in Go

**Composite Literals Are Unaddressable But Can Take Addresses**
Generally, only addressable values can take addresses. But there is syntactic sugar in Go, which allows us to take addresses on composite literals.

```go
func main() {
	type Book struct {
		Pages int
	}
	// Book{100} is unaddressable but can 
	// be taken address
	p := &Book{100} // tmp := Book{100}; p := &tmp
	p.Pages = 200
}
```

**About Struct Value Comparisons**
A struct type is comparable only if none of the types of its fields are incomparable. Two struct values are comparable only if they can be assigned to each other and their types are both comparable.

## Value parts

**Two Categories of Go Types**

Each C value in memory occupies one memory block (one continuous memory segment). However, a value of some kinds of Go types may often hosted on more than one memory block. We call the parts (being distributed on different memory blocks) of a value are value parts. A memory value hosting on more than one memory blocks is composed of one direct value part and serveral underlying indirect parts which are referenced by that direct value part.

|Types whose values each is only hosted on one single memory block|Types whose values each may be hosted on multiple memory blocks|
|-|-|
|Solo Direct Value Part|Direct Part -> Underlying Part|
|boolean types|slice types|
|numeric types|map types|
|pointer types|channel types|
|unsafe pointer types|function types|
|struct types|interface types|
|array types|string types|

**Two Kinds of Pointer Types in Go**

A pointer value stores a memory address of another value, unless the pointer value is a nil pointer. We can say the pointer value references the other value, or the other value is referenced by the pointer value. Values can also be referenced indirectly.
- If a struct value a has a pointer field b which references a value c, then we can say the struct value a also references value c.
- If a value x references (either directly or indirectly) a value y, and the value y references (either directly or indirectly) a value z, then we can also say the value x (indirectly) references the value z.

Below, we call a struct type with fields of pointer types as a pointer wrapper type, and call a type whose values may contains (either directly or indirectly) pointers a pointer holder type. Pointer types and pointer wrapper types are all pointer holder types.

## Arrays, Slices and Maps in Go
**Composite Literals Are Unaddressable but Can Be Taken Addresses**

We have learned that struct composite literals can be taken addresses directly. Container composite literals have no exception here.

```go
func main() {
	pm := &map[string]int{"c":1972, "Go": 2009}
	ps := &[]string{"break", "continue"}
	pa := &[...]bool{false, true, true, false}
	fmt.Printf("%T\n", pm) // *map[string]int
	fmt.Printf("%T\n", ps) // *[]string
	fmt.Printf("%T\n", pa) // *[4]bool
}
```

**Compare Container Values**

Map and slice types are incomparable types. So map and slice types can't be used as map key types. Although a slice or map value can't be compared with another slide or map value (or itself), it can be compared to the bare untyped nil identifier to check whether or not the slice or map value is zero value.

**Retrieve and Modify Container Elements**
The element associated to key k stored in a container value v is represented with the element indexing syntax from v[k]

**Recall the Internal Structure Definition of Slice Types**
```go
type _Slice struct {
	elements unsafe.Pointer // referencing underlying elements
	len int
	cap int
}
```

When the slice is used as the base slice in an append function call
- If the number of appended elements is larger than the number of the redundant elements slots of the base slice, a new underlying memory segment will be allocated for the result slice, thus the result slice and the base slice will not share any elmenets.
- Otherwise, no new underlying memory segments will be allocated for the result slice, and the elements of the base slice also belong to the elements of the result slice. In other words, the two slices share some elements and all of their element s are hosted on the same underlying memory segment.

**Container Assignment**
If a map is assigned to another map, the the two maps will share all (underlying) elements. Appending elements into (or deleting elements from) one map will reflect on the other map.

Like map assignments, if a slice is assigned to another slice, they will share all (underlying) elements. Their respective lengths and capacities equal to each other. However, if the length/capacity of one slice changes later, the change will not reflect on the other slice.

When an array is assigned to another array, all the elements are copied from the source one to the destination one. The two arrays don't share any elements.

**Append and Delete Container Elements**

## Go Value Copy Costs
Value copying happens frequently in Go programming. Values assignments, argument passing and channel value send operations are all value copying involved.

|Kinds of Types|Value Size|
|-|-|
|bool|1 bytes|
|int8,uint8|1 byte|
|int16, uint16|2 bytes|
|int32, uint32, float32, rune|4 bytes|
|int64, uint64, float64|8 bytes|
|int, uint|1 word|
|uintptr|1 word|
|string|2 words|
|pointer| 1 word|
|slice|3 words|
|map|1 word|
|channel|1 word|
|function|1 word|
|interface|2 words|
|array|element value size * array length|

**Value Copy Costs**

In practice, we can view struct values with less than 5 fields and with sizes not larger than four native words as small-size values.

For the standard Go compiler, except values of large-size struct and array types, other types in Go are all small-size types.

To avoid large value copy costs in argument passing and channel value send and receive operations, we should try to avoid using large-size struct and array types as function and method pararameter types (including method receiver types) and channel elemement types. We can use pointer types whose base types are large-types instead for such scenarios.

One the other hand, we should also consider the fact that too many pointers will increase the pressure of garbage collectors at run time. So whether large-size struct and array types or their corresponding pointer types should be used relies on specific circumstances.

Generally, in practice, we seldom use pointer types whose base types are slice types, map types, channel types, function types, string types and interface types. The costs of copying values of these assumed base types are very small.

We should also try to avoid using the two-iteration-variable forms to iterate array and slice elements if the element types are large-size types, for each element value will be copied to the second iteration variable in the iteration process.

## Bounds Check Elimination

In array/slice element indexing and subslice operations, Go runtime will check whether or note the involved indexes are out of range. If an index is out of range, a panic will be produced to prevent the invalid index from doing harm. This is called bounds check. Bounds checks make our code run safely, on the other hand, they also make our code run a little slower. Go provides some optimization.

```go
func f1(s []int) {
	_ = s[0] // bounds check
	_ = s[1] // bounds check
	_ = s[2] // bounds check
}

func f2(s []int) {
	_ = s[2] // bounds check
	_ = s[1] // bounds check eliminated
	_ = s[0] // bounds check eliminated
}

func f3(s []int, index int) {
	_ = s[index] // bounds check
	_ = s[index] // bounds check eliminated
}

func f4(a [5]int) {
	_ = a[4] // bounds check eliminated
}
```


## Memory Order Guarantees in Go

**About Memory Ordering**

Many compilers (at compile time) and CPU processors (at run time) often make some optimizations by adjusting the instruction orders, so that the instruction execution orders may differ from the orders presented in code. Instruction ordering is also called memory ordering.

Surely, instruction reordering can't be arbitrary. The basic requirement for a reordering inside a specified goroutine is the reordering must not be detectable by the goroutine itself if the goroutine doesn't share data with other goroutines. In other words, from the perspective of such a goroutine, it can think its instruction execution order is always the same as the order specified by code, even if instruction reordering really happens inside it.

However, if some goroutines share some data, then instruction reordering happens inside one of these goroutine may be observed by the others goroutines, and affect the behaviors of all these goroutines. Sharing data between goroutines is common in concurrent programming. If we ignore the results caused by instruction reordering, the behaviors of our concurrent programs might compiler and CPU dependent, and often abnormal.

Here is an unprofessional Go program which doesn't consider instruction reordering. 

```go
var a string
var done bool

func setup() {
	a = "hello, world"
	done = true
	if done {
		log.Println(len(a)) // always 12 once printed
	}
}

func main() {
	go setup()
	for !done {
		runtime.Gosched()
	}
	log.Println(a) // expected to print: Hello, world
}
```
The behavior of this program is very possible as we expect, a hello, world will be printed. However, the behavior of this program is compiler and CPU dependent. If the program is compiled with a different compiler, or with a later compiler version, or it runs on a different architecture, the hello, world might not be printed, or a text different from hello, world might be printed. The reason is compilers and CPUs may exchange the execution orders of the first two lines in the setup function, so the final effect of the setup function may become to

```go
func setup() {
	done = true
	a = "hello, world"
	if done {
		log.Println(len(a))
	}
}
```

The setup goroutine in the above program is unable to observe the reordering, so the log.Println(len(a)) line will always print 12 (if this line gets executed before the program exits). However, the main goroutine may observe the reordering, which is why the printed text might not be hello, world.

Besides the problem of ignoring memory reordering, there are data races in the program. There are not any synchronizations made in using the variable a and done.

**Go Memory Model**

**The creation of a goroutine happens before the execution of the goroutine**
In the following function, the assignment x, y = 123, 789 will be executed before the call fmt.Println(x) and the call fmt.Println(x) will be executed before the call fmt.Println(y)

```go
var x, y int
func f1() {
	x, y = 123, 789
	go func() {
		fmt.Println(x)
		go func() {
			fmt.Println(y)
		}()
	}()
}
```

However, the execution orders of the three in the following function are not deterministic. There are data races in this function.
```go
var x, y int
func f2() {
	go func() {
		// Might print 0, 123, or some others
		fmt.Println(x)
	}()
	go func() {
		// Might print 0, 789, or some others
		fmt.Println(y)
	}()
	x, y = 123, 789
}
```

**Channel operations related order guarantees**

Go 1 memory model lists the following three channel related order guarantees 

- The nth successful send to a channel happens before the nth successful receive from that channel completes, no matter that channel is buffered or unbuffered.
- The nth successful receive from a channel with capacity m happens before the (n+m)th successful send to that channel completes.
- The closing of a channel happens before a receive completes if the receive returns a zero value because the channel is closed.

## Common Concurrent Programming Mistakes

**No Synchronizations When Synchronizations Are Needed**

**Leave Goroutines Hanging**

**Not Pay Attention to Too Many Resources Are Consumed by Calls to the time.After function**

The After function in the time standard package returns a channel for delay notification. The function is convenient, however each of its calls will create a new value of time.Timer type. The new created Timer value will keep alive in the duration specified by the passed argument to the After function. If the function is called many times in certain period, there will be many alive Timer values accumulated so that much memory and computation is consumed.

## Memory Blocks

## 27. Reflections in Go

In Go, we can create a reflect.Type value from an arbitray non-interface value by calling the reflect.TypeOf function. The result of reflect.Type value represents the type of the non-inteface value. Surely, we can also pass an interface value of a reflect.TypeOf function call, but the call will return a reflect.Type value which represents the dynamic type of the interface value.

**Inspect struct field tags through reflection**
```go
type T struct {
	X    int  `max:"99" min:"0" default:"0"`
	Y, Z bool `optional:"yes"`
}

func main() {
	t := reflect.TypeOf(T{})
	x := t.Field(0).Tag
	y := t.Field(1).Tag
	z := t.Field(2).Tag

	fmt.Println(x, y, z)
	fmt.Println(reflect.TypeOf(x))
	v, present := x.Lookup("max")
	fmt.Println(len(v), present, v)
	fmt.Println(x.Get("max"))
	fmt.Println(x.Lookup("optional"))
	fmt.Println(y.Lookup("optional"))
	fmt.Println(z.Lookup("optional"))
}
```

- Tag keys may not contain space, quote and colon
- To form a valid key-value pair, no space characters are allowed to follow the semicolon in the supposed key-value pair. So `optional: "yes"` doesn't form key-value pairs.
- Space characters in tag values are important `json:"author, omitempty"`, `json:" author,omitempty"`, `json:"author,omitempty"` are different.


## Channels in Go

The information in this article may be sightly challenging for new gophers. Some parts of this article may need to be read several times to be fully understood.

### Channel Introduction

One suggestion (made by Rob Pike) for concurrent programming is **don't communicate by sharing memory, share memory by communicating.**

Communicating by sharing memory and sharing memory by communicating are two programming manners in concurrent programming. When goroutines communicate by sharing memory, we use traditional concurrency synchronization techniques, such as mutex locks, to protect the shared memory to prevent data races. We can use channels to implement sharing memory by communicating.


### Channel Value Comparisons

All channel types are comparable types.
From the article value parts, we know that non-nil channel values are multi-part values. If not channel value is assigned to another, the two channels share the same underlying part(s). In other words, those two channels represent the same internal channel object. The result of comparing them is true.

### Channel Operations

There are five channel specified operations. Assume the channel is ch, their syntax and function calls of these operations are listed here. (i) close, (ii) send value to channel, (iii) receive value from channel, (iv) query the value buffer capacity, (v) query the current of values n the buffer (or the length).

Most basic operations in Go are not synchronized. In other words, they are not concurrency-safe. These operations include value assignments, argument passing and container element manipulations, etc. However, all the just introduced channel operations are already synchronized, so no further synchronizations are needed to safety perform these operation.

Like most other operations in Go, channel value assignments are not synchronized. Similarly, assigning the received value to another value is also not synchronized, though any channel receive operation is synchronized.

### Detailed Explanation for Channel Operations


|Operation|A Nil Channel|A Closed Channel|A Not-Closed Non-nil Channel|
|-|-|-|-|
|Close|Panic|Panic|Success to close(C)|
|Send Value To|Block for ever|Panic|Block or succeed to send(B)|
|Receive Value From|Block for ever|Never block(D)|Block or succeed to receive(A)|

### Channel Element Values Are Transferred by Copy

When a value if transferred from one goroutine to another goroutine, the value will be copied at least one time. If the transferred value ever stayed in the value buffer of a channel, then two copies will happen in transfer process. One copy happens when the value is copied from the sender goroutine into the value buffer, the other happens when the value is copied from the value buffer to the receiver goroutine. So if the passed value size is too large, it is best to use a pointer element type instead, to avoid a large value copy cost. 

### The Implementation of the Select Mechanism

There are several steps to execute a select-case block:
1. Evaluate all involved channel expression and value expressions to be potentially sent in case operations, from top to bottom and left to right

## Channel Use Cases

The remaining of this article will show many channel use cases. I hope this article will convince you that:

- Asynchronous and concurrency programming with Go channels is easy and enjoyable.
- The channel synchronization technique has a wider range of uses and has more variations than the synchronization solutions used in some other languages, such as the actor mode and the async/await pattern.

### Use Channels as Futures/Promises

Futures and promises are used in many other popular languages. They are often associated with requests and responses.

**Return receive-only channels (async) as results**

In the following example, the values of two arguments of the sumSquares function call are requested concurrently. Each of the two channel receive operations will block until a send operation performs on the corresponding channel. It takes about three seconds instead of six seconds to return the final result. 

```go
func main() {
	now := time.Now()
	rand.Seed(time.Now().Unix())
	// async
	a, b := longTimeRequest(), longTimeRequest()

	// wait async result
	fmt.Println(sumSquares(<-a, <-b))
	fmt.Println("since: ", time.Since(now))
}

func longTimeRequest() <-chan int32 {
	r := make(chan int32)
	go func() {
		// Simulate a workload
		time.Sleep(time.Second * 3)
		r <- rand.Int31n(100)
		close(r)
	}()

	return r
}

func sumSquares(a, b int32) int32 {
	return a*a + b*b
}
```

**Pass send-only channels as arguments**

```go
func main() {
	now := time.Now()
	rand.Seed(time.Now().Unix())
	r := make(chan int32, 2)
	// async
	go longTimeRequest(r)
	go longTimeRequest(r)

	// wait async result
	fmt.Println(sumSquares(<-r, <-r))
	fmt.Println("since: ", time.Since(now))
}

func longTimeRequest(r chan<- int32) {
	time.Sleep(time.Second)
	r <- rand.Int31n(100)
}

func sumSquares(a, b int32) int32 {
	return a*a + b*b
}
```
### The first response wins

Sometimes, a piece of data can be received from several sources to avoid high latencies. For a lot of factors, the response durations of these sources may vary much. Even for a specified source, its response durations are also not constant. To make the response duration as short as possible, we can send a request to every source in a separated goroutine. Only the first response will be used, other slower ones will be discarded.

```go
func main() {
	rand.Seed(time.Now().UnixNano())

	startTime := time.Now()
	// c must be a buffered channel
	c := make(chan int32, 5)
	for i := 0; i < cap(c); i++ {
		go source(c)
	}

	// Only the first response will be used
	rnd := <-c
	fmt.Println(time.Since(startTime))
	fmt.Println(rnd)
}

func source(c chan<- int32) {
	ra, rb := rand.Int31(), rand.Intn(3)+1
	// Sleep 1s/2s/3s
	time.Sleep(time.Duration(rb) * time.Second)
	c <- ra
}
```

Problem: unnecessary computation run in background

```go
func main() {
	rand.Seed(time.Now().UnixNano())
	ctx := context.Background()
	ctx, cancel := context.WithCancel(ctx)

	// c must be a buffered channel
	c := make(chan int32, 5)
	for i := 0; i < cap(c); i++ {
		go source(ctx, c)
	}

	// Only the first response will be used
	rnd := <-c
	cancel()

	fmt.Println(rnd)
	time.Sleep(time.Second * 5)
}

var client = http.DefaultClient

func source(ctx context.Context, c chan<- int32) {
	now := time.Now()
	req, _ := http.NewRequest(http.MethodGet, "http://localhost:8081", nil)
	req = req.WithContext(ctx)
	resp, err := client.Do(req)
	if err != nil {
		log.Println("err: ", err)
	} else {
		data, _ := ioutil.ReadAll(resp.Body)
		resp.Body.Close()
		log.Println("data: ", string(data), time.Since(now))

	}
	c <- rand.Int31()
}
```
Sometimes, a request is not guaranteed to be responded back a valid value. For all kinds of reasons, an error may be returned instead. For such cases, we can use a struct type like struct{v T; err error} or a blank interface type as the channel element type.

### Use Channels for Notifications

**1-to-1 notification by sending a value to a channel**

If there are no values to be received from a channel, then the next receive operation on the channel will block until another goroutine sends a value to the channel. So we can send a value to a channel to notify another goroutine which is waiting to receive a value from the same channel.

```go
func main() {
	done := make(chan struct{})

	go func() {
		// Notify job is done
		log.Println("notify job is done")
		done <- struct{}{}
	}()

	// waiting here for notification
	<-done
}
```

**N-to-1 notifications by WaitGroup**

**Broadcast 1-to-N notifications by closing a channel**

```go
func main() {
	now := time.Now()
	notify := make(chan struct{})

	go func() {
		<-notify // receive from closed channel never block
		fmt.Println("since: ", time.Since(now))
	}()
	go func() {
		<-notify // receive from closed channel never block
		fmt.Println("since: ", time.Since(now))
	}()

	time.Sleep(time.Second)
	close(notify) // 1 to N notification
	time.Sleep(time.Second)
}
```

### Use Channels as Counting Semaphores

Buffered channels can be used as counting semaphores. Counting semaphores can be viewed as multi-owner locks. If the capacity of channel is N, then it can be viewed as a lock which can have most N owners at any time. Binary semaphores (mutexes) a special counting semaphores, each of binary semaphores can have at most one owner at any time.

## Go memory model

The Go memory model specifies the conditions under which reads of a variable in one goroutine can be guaranteed to observe values produced by writes to the same variable in a different goroutine.

**Advice**

Programs that modify data being simultaneously accessed by multiple goroutines must serialize such access.
To serialize access, protect the data with channel operations or other synchronization primitives such as those in the sync and sync/atomic packages.

**Informal Overview**

A data race is defined as a write to a memory location happening concurrently with another read or write to that same location, unless all the accesses involved are atomic data accesses as provided by sync/atomic package. As noted already, programmers are strongly encouraged to use appropriate synchronization to avoid data races. As noted already, programmers are strongly encouraged to use appropriate synchronization to avoid data races. In the absence of data races, Go programs behave as if all the goroutines were multiplexed onto a single processor. This property is sometimes referred to as DRF-SC: data-race-free programs execute in a sequentially consistent manner.

### Memory model

The memory model describes the requirements on program executions, which are made up of goroutine executions, which in turn are made up of memory operations.

A memory operation is modeled by four details:
- Its kind, indicating whether it is an ordinary data read, an ordinary data write, or a synchronizing operation such as an atomic data access, a mutex operation or a channel operation.
- Its location in the program
- The memory location or variable being accessed
- The values read or written by the operation.

Some memory operations are read-like, including read, atomic read, mutex lock, and channel receive. Other memory operations are write-like, including write, atomic write, mutex lock channel send and channel close. Some, such as atomic compare-and-swap, are both read-like and write-like.

A goroutine execution is modeled as a set of memory operations executed by a single goroutine.

**Requirement 1:** The memory operations in each goroutine must correspond to a correct sequential execution of that goroutine, given the values read from and written to memory. That execution must be consistent with the sequenced before relation.

**Requirement 2:** For a given program execution

### Implementation Restrictions for Programs Containing Data Races

### Synchronization

**Initialization**
Program initialization runs in a single goroutine, but that goroutine may create other goroutines, which run concurrently.

**Goroutine creation**
The go statement that starts a new goroutine is synchronized before the start of the goroutine's execution.

```go
var a string
func f()  {
	print(a)
}

func hello() {
	a = "hello, world"
	go f() // go statement that starts a new goroutine is synchronized before the start of the goroutine's execution.
}
```

**Goroutine destruction**
The exit of a goroutine is not guaranteed to be synchronized before any event in the program 

```go
var a string
func hello() {
	go func() {
		a = "hello"  // assignment to a is not followed by any synchronization event, so it is not guaranteed to be observed by any other goroutine. In fact, an aggressive compiler 
		// might delete the entire go statement
	}()

	print(a)
}
```
Check mail xem có join luôn được không hay phải đợt thầy accept

### Finalizers

### Incorrect synchronization

Programs with races are incorrect and can exhibit non-sequentially consistent executions. In particular, note that a read r may observe the value written by any write w that executes concurrently with r. Even if this occurs, it does not imply that reads happening after r will observe writes that happened before w.

```go
var a, b int
func f() {
	a = 1
	b = 2
}

func g() {
	print(b)
	print(a)
}

func main() {
	go f()
	g()
}
```

## $38. How to Gracefully Close Channels

- No easy and universal ways to check whether or not a channel is closed without modifying the status of the channel.
- Closing a closed channel will panic, so it is dangerous to close a channel if the closers don't know whether or not the channel is closed.
- Sending values to a closed channel will panic, so it is dangerous to send values to a channel if the senders don't know whether or not the channel is closed.

There is really not a built-in function to check whether or not a channel has been closed.

There is indeed a simple method to check whether or not a channel is closed if you can make sure no values were (and will be) ever sent to the channel.

```go
func main() {
	ch := make(chan struct{})
	close(ch)

	select {
	case <-ch:
		log.Println("channel is closed")
		return
	default:
	}
}
```

As above mentioned, this is not a universal way to check whether a channel is closed.

**The Channel Closing Principle**

One general principle of using Go channels is don't close a channel from the receiver side and don't close a channel if the channel has multiple concurrent senders. In other words, we should only close a channel in a sender goroutine if the sender is the only sender of the channel.
Surely, this is not a universal principle to close channels. The universal principle is don't close (or send value to) closed channels. If we can guarantee that no goroutines will close and send values to a non-closed non-nil channel any more, then a goroutine can close the channel safely. 

**Solutions Which Close Channels Rudely**

If you would close a channel from the receiver side or in one of the multiple senders of the channel anyway, then you can use the recover mechanism to prevent the possible panic from crashing your program.

```go
func SafeClose(ch chan struct{}) (justClosed bool) {
	defer func() {
		if recover() != nil {
			// The return result can be altered
			// in a defer function call
			justClosed = false
		}
	}()

	close(ch)
	return true // <=> justClosed = true; return
}
```
This solution obviously breaks the channel closing principle.
The same idea can be used for sending values to potential closed channel.

```go
func SafeSend(ch chan T, value T) (closed bool) {
	defer func() {
		if recover() != nil {
			closed = true
		}
	}()

	ch <- value
}
```

**Solutions Which Close Channels Politely**

Many people using sync.Once to close channels:

```go
type MyChannel struct {
	C    chan int
	once sync.Once
}

func NewMyChannel() *MyChannel {
	return &MyChannel{
		C: make(chan int),
	}
}

func (mc *MyChannel) SafeClose() {
	mc.once.Do(func() {
		close(mc.C)
	})
}
```

Surely, we can also use sync.Mutex to avoid closing a channel multiple times

```go
type MyChannel struct {
	C      chan int
	closed bool
	mutex  sync.Mutex
}

func NewMyChannel() *MyChannel {
	return &MyChannel{
		C:      make(chan int),
	}
}

func (mc *MyChannel) SafeClose() {
	mc.mutex.Lock()
	defer mc.mutex.Unlock()
	if !mc.closed {
		close(mc.C)
		mc.closed = true
	}
}

func (mc *MyChannel) IsClosed() bool {
	mc.mutex.Lock()
	defer mc.mutex.Unlock()
	return mc.closed
}
```
These ways may be polite, but they may not avoid data races. Currently, Go specification doesn't guarantee that there are no data races happening when a channel close and a channel send operations are executed concurrently. If a SafeClose function is called concurrently with a channel send operation to the same channel, data races might happen.

### Solutions Which Close Channels Gracefully

**1. M receives, one sender, the sender says "no more sends" by closing the data channel**
This is the simplest situation, just let the sender close the data channel when it doesn't want to send more

```go
rand.Seed(time.Now().UnixNano())
const Max = 100000
const NumReceivers = 100

wgReceivers := sync.WaitGroup{}
wgReceivers.Add(NumReceivers)

dataCh := make(chan int)

// the sender
go func() {
	for {
		if value := rand.Intn(Max); value == 0 {
			// The only sender can close the channel at any time safely
			close(dataCh)
			return
		} else {
			dataCh <- value
		}
	}
}()

// receivers
for i := 0; i < NumReceivers; i++ {
	go func() {
		defer wgReceivers.Done()

		// Receive values until dataCh is
		// closed and the value buffer queue
		// of dataCh becomes empty.
		for value := range dataCh {
			log.Println(value)
		}
	}()
}

wgReceivers.Wait()
```

**2. One receiver, N senders, the only receiver says "please stop sending more" by closing an additional signal channel (1-to-n) notification**

```go
func main() {
	rand.Seed(time.Now().UnixNano())

	const Max = 100000
	const NumSenders = 1000

	wgReceivers := sync.WaitGroup{}
	wgReceivers.Add(1)

	dataCh := make(chan int)
	// stopCh is an additional signal channel
	stopCh := make(chan struct{})

	// senders
	for i := 0; i < NumSenders; i++ {
		go func() {
			for {
				// The try-receiver operation is to try to exit
				// the goroutine as early as possible. For this specified example
				// it is not essential.
				// TODO: extract to ctx.Done() example
				select {
				case <-stopCh:
					return
				default:
				}

				select {
				case <-stopCh:
					return
				case dataCh <- rand.Intn(Max):
				}
			}
		}()
	}

	// the receiver
	go func() {
		defer wgReceivers.Done()

		for value := range dataCh {
			if value == Max-1 {
				close(stopCh)
				return
			}
			log.Println(value)
		}
	}()

	wgReceivers.Wait()

}
```

In this example, the channel dataCh is never closed. Yes, channels don't have to be closed. A channel will be eventually garbage collected if no goroutines reference it any more, whether is is closed or not. So the gracefulness of closing a channel here is not to close the channel.

**3. M receivers, N senders, any one of them says "let's end the game" by notifying a moderator to close an additional signal channel**

This is the most complicated situation. We can't let any of the receivers and the senders close the data channel. And we can't let any of the receivers close an additional signal channel to notify all senders and receivers to exit the game. Doing either will break the channel closing principle. However, we can introduce a moderator role to close the additional signal channel.  

```go
func main() {
	rand.Seed(time.Now().UnixNano())
	const Max = 100000
	const NumReceivers = 10
	const NumSenders = 1000

	wgReceivers := sync.WaitGroup{}
	wgReceivers.Add(NumReceivers)

	dataCh := make(chan int)
	// stopCh is an additional signal channel
	// Its sender is the moderator goroutine, and its receivers are all senders and receiver
	stopCh := make(chan struct{})
	// the channel toStop is used to notify the moderator to close the additional signal channel (stopCh)
	toStop := make(chan string)

	var stoppedBy string

	// moderator
	go func() {
		stoppedBy = <-toStop
		close(stopCh)
	}()

	// senders
	for i := 0; i < NumSenders; i++ {
		go func(id string) {
			for {
				value := rand.Intn(Max)
				if value == 0 {
					// Here, try-send operator is to notify the moderator to close the additional signal channel
					// we can't close(stopCh) here because concurrency and close closed channel problem
					select {
					case toStop <- "sender#" + id:
					default:
					}
					return
				}

				// The try-receive operation here is to try to exit the sender goroutine as early as possible. Try-receiver and try-send select blocks are specially optimized by the standard go compiler
				select {
				case <-stopCh:
					return
				default:
				}

				// Even if stopCh is closed, the first brand in this select block might be still not selected for some loops if the the send to dataCh is also non-blocking. If this is unacceptable,
				// then the above try-receive operation is essential
				select {
				case <-stopCh:
					return
				case dataCh <- value:
				}
			}
		}(strconv.Itoa(i))
	}

	// receivers
	for i := 0; i < NumReceivers; i++ {
		go func(id string) {
			defer wgReceivers.Done()
			for {
				select {
				// Same as the sender goroutine, the try-receive operation here is to try to exit the receiver goroutine as early as possible
				case <-stopCh:
					return
				default:
				}

				// Even if stopCh is closed, the first
				// branch in this select block might be
				// still not selected for some loops
				// (and forever in theory) if the receive
				// from dataCh is also non-blocking. If
				// this is not acceptable, then the above
				// try-receive operation is essential.
				select {
				case <-stopCh:
					return
				case value := <-dataCh:
					if value == Max-1 {
						select {
						case toStop <- "receiver#" + id:
						default:
						}
					}
					log.Println(value)
				}
			}

		}(strconv.Itoa(i))
	}

	wgReceivers.Wait()
	log.Println("stopped by", stoppedBy)
}

```

**4. A variant of the "M receiver, one sender" situation: the close request is made by a third-party goroutine**